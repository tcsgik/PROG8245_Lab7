{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b479e93",
   "metadata": {},
   "source": [
    "# üß† NLP Foundations Workshop: From Preprocessing to tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c04c3",
   "metadata": {},
   "source": [
    "\n",
    "**Duration**: 90 minutes  \n",
    "**Team Size**: 3 students  \n",
    "**Objective**: Build an NLP pipeline from scratch to implement and test six foundational concepts in Natural Language Processing in preparation for Vector Space Models and Cosine Similarity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5e0c14",
   "metadata": {},
   "source": [
    "## Step 1: Presenting the Six Core NLP Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b7f198",
   "metadata": {},
   "source": [
    "### üîπ Term-Document Incidence Matrix\n",
    "\n",
    "The **Term-Document Incidence Matrix** is a binary matrix that shows whether a term $t$ appears in a document $d$.\n",
    "\n",
    "- Rows represent terms in the vocabulary  \n",
    "- Columns represent documents in the corpus  \n",
    "- Each entry $w_{t,d}$ is defined as:\n",
    "\n",
    "$$\n",
    "w_{t,d} =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } t \\in d \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "This is a **binary representation** ‚Äî it only records the **presence or absence** of a term, not how many times it appears.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Why Use It?\n",
    "\n",
    "- It‚Äôs the **simplest form** of representing document contents using structured data.\n",
    "- Useful for:\n",
    "  - Boolean search and keyword filters\n",
    "  - Document classification based on keyword sets\n",
    "  - Building foundational **retrieval systems**\n",
    "- Helps in detecting whether **all query terms exist** in a document (e.g., phrase queries or \"AND\" operations)\n",
    "\n",
    "---\n",
    "\n",
    "#### üìò Example\n",
    "\n",
    "Suppose we have 3 documents:\n",
    "\n",
    "- **Doc1**: \"machine learning is fun\"  \n",
    "- **Doc2**: \"deep learning is powerful\"  \n",
    "- **Doc3**: \"machine learning and deep models\"\n",
    "\n",
    "The vocabulary extracted from all three is:\n",
    "\n",
    "**Vocabulary** = {machine, learning, is, fun, deep, powerful, and, models}\n",
    "\n",
    "The Term-Document Incidence Matrix would look like:\n",
    "\n",
    "| Term       | Doc1 | Doc2 | Doc3 |\n",
    "|------------|------|------|------|\n",
    "| machine    | 1    | 0    | 1    |\n",
    "| learning   | 1    | 1    | 1    |\n",
    "| is         | 1    | 1    | 0    |\n",
    "| fun        | 1    | 0    | 0    |\n",
    "| deep       | 0    | 1    | 1    |\n",
    "| powerful   | 0    | 1    | 0    |\n",
    "| and        | 0    | 0    | 1    |\n",
    "| models     | 0    | 0    | 1    |\n",
    "\n",
    "For example:\n",
    "- $w_{\\text{machine}, \\text{Doc1}} = 1$ ‚Üí \"machine\" is in Doc1\n",
    "- $w_{\\text{powerful}, \\text{Doc1}} = 0$ ‚Üí \"powerful\" is not in Doc1\n",
    "\n",
    "This matrix is particularly helpful when implementing **Boolean retrieval systems** and **phrase matching**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a14ef537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Term-Document Incidence Matrix:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "and",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "deep",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fun",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "learning",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "machine",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "models",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "powerful",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "4d0ee3a3-b080-444d-85cd-0d5a697d0a8e",
       "rows": [
        [
         "Doc1",
         "0",
         "0",
         "1",
         "1",
         "1",
         "1",
         "0",
         "0"
        ],
        [
         "Doc2",
         "0",
         "1",
         "0",
         "1",
         "1",
         "0",
         "0",
         "1"
        ],
        [
         "Doc3",
         "1",
         "1",
         "0",
         "0",
         "1",
         "1",
         "1",
         "0"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>deep</th>\n",
       "      <th>fun</th>\n",
       "      <th>is</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>models</th>\n",
       "      <th>powerful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      and  deep  fun  is  learning  machine  models  powerful\n",
       "Doc1    0     0    1   1         1        1       0         0\n",
       "Doc2    0     1    0   1         1        0       0         1\n",
       "Doc3    1     1    0   0         1        1       1         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üìò Example: Term-Document Incidence Matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Sample corpus from the Markdown example\n",
    "docs = [\n",
    "    \"machine learning is fun\",          # Doc1\n",
    "    \"deep learning is powerful\",        # Doc2\n",
    "    \"machine learning and deep models\"  # Doc3\n",
    "]\n",
    "\n",
    "# Use binary=True to indicate presence/absence (1 or 0)\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "\n",
    "# Fit and transform the corpus\n",
    "X = vectorizer.fit_transform(docs)\n",
    "\n",
    "# Create a labeled DataFrame\n",
    "incidence_matrix = pd.DataFrame(X.toarray(),\n",
    "                                index=[\"Doc1\", \"Doc2\", \"Doc3\"],\n",
    "                                columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the incidence matrix\n",
    "print(\"üîé Term-Document Incidence Matrix:\")\n",
    "display(incidence_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253bc6a1",
   "metadata": {},
   "source": [
    "üó£Ô∏è **Instructor Talking Point**: This code demonstrates how the presence or absence of a term in a document is encoded as a binary matrix ‚Äî foundational for Boolean retrieval. Explain this with respect to a future AI agent (chatbot) builds context.\n",
    "<br/>\n",
    "<br/>\n",
    "üß† **Student Talking Point**: Add a phrase query (e.g., 'machine learning') and explain your reasoning as to how you would check if both terms occur in a single document using this matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e547ea",
   "metadata": {},
   "source": [
    "### üîπ Term Frequency (TF)\n",
    "\n",
    "**Term Frequency (TF)** measures how frequently a term $t$ appears in a document $d$.\n",
    "\n",
    "$$\n",
    "tf_{t,d} = f_{t,d}\n",
    "$$\n",
    "\n",
    "Where $f_{t,d}$ is the raw count of term $t$ in document $d$.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Why Use It?\n",
    "\n",
    "- TF reflects the importance of a word **within a specific document**.\n",
    "- A higher TF means the term is likely central to the topic of that document.\n",
    "- It's used as the **first step** in vectorizing text for machine learning models like classification, clustering, or information retrieval.\n",
    "\n",
    "TF is most effective when combined with **IDF** (Inverse Document Frequency) to balance against very common terms across the corpus.\n",
    "\n",
    "---\n",
    "\n",
    "#### üìò Example\n",
    "\n",
    "Let‚Äôs say we have this document:\n",
    "\n",
    "> **Doc1**: `\"machine learning is fun and machine learning is useful\"`\n",
    "\n",
    "Calculate raw term counts:\n",
    "\n",
    "| Term     | Raw TF $(f_{t,d})$ |\n",
    "|----------|--------------------|\n",
    "| machine  | 2                  |\n",
    "| learning | 2                  |\n",
    "| is       | 2                  |\n",
    "| fun      | 1                  |\n",
    "| and      | 1                  |\n",
    "| useful   | 1                  |\n",
    "\n",
    "If normalized (total of 9 words):\n",
    "\n",
    "- $tf(\\text{\"machine\"}, \\text{Doc1}) = \\frac{2}{9} \\approx 0.22$\n",
    "- $tf(\\text{\"learning\"}, \\text{Doc1}) = \\frac{2}{9} \\approx 0.22$\n",
    "\n",
    "This simple frequency can then be used as input into models such as **TF-IDF**, which adjusts these values based on how rare the words are across multiple documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b512919b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Raw Term Frequencies:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Term",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Raw TF",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "ab55a898-70e2-4ec2-8b89-b47ca9d12e6f",
       "rows": [
        [
         "0",
         "machine",
         "2"
        ],
        [
         "1",
         "learning",
         "2"
        ],
        [
         "2",
         "is",
         "2"
        ],
        [
         "3",
         "fun",
         "1"
        ],
        [
         "4",
         "and",
         "1"
        ],
        [
         "5",
         "useful",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Raw TF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>machine</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>learning</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fun</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>useful</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Term  Raw TF\n",
       "0   machine       2\n",
       "1  learning       2\n",
       "2        is       2\n",
       "3       fun       1\n",
       "4       and       1\n",
       "5    useful       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìè Normalized Term Frequencies:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Term",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TF (Normalized)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d08b934a-0ebe-4f6d-a6f1-cff09e560aad",
       "rows": [
        [
         "0",
         "machine",
         "0.2222222222222222"
        ],
        [
         "1",
         "learning",
         "0.2222222222222222"
        ],
        [
         "2",
         "is",
         "0.2222222222222222"
        ],
        [
         "3",
         "fun",
         "0.1111111111111111"
        ],
        [
         "4",
         "and",
         "0.1111111111111111"
        ],
        [
         "5",
         "useful",
         "0.1111111111111111"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>TF (Normalized)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>machine</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>learning</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fun</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>useful</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Term  TF (Normalized)\n",
       "0   machine         0.222222\n",
       "1  learning         0.222222\n",
       "2        is         0.222222\n",
       "3       fun         0.111111\n",
       "4       and         0.111111\n",
       "5    useful         0.111111"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üìò Example: Term Frequency (TF)\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Sample document\n",
    "doc1 = \"machine learning is fun and machine learning is useful\"\n",
    "\n",
    "# Tokenize the document (simple lowercase + split)\n",
    "tokens = doc1.lower().split()\n",
    "\n",
    "# Count term frequencies\n",
    "tf_raw = Counter(tokens)\n",
    "\n",
    "# Total number of words\n",
    "total_terms = len(tokens)\n",
    "\n",
    "# Compute normalized TF\n",
    "tf_normalized = {term: count / total_terms for term, count in tf_raw.items()}\n",
    "\n",
    "# Display results\n",
    "print(\"üî¢ Raw Term Frequencies:\")\n",
    "display(pd.DataFrame(tf_raw.items(), columns=[\"Term\", \"Raw TF\"]))\n",
    "\n",
    "print(\"\\nüìè Normalized Term Frequencies:\")\n",
    "display(pd.DataFrame(tf_normalized.items(), columns=[\"Term\", \"TF (Normalized)\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5e206",
   "metadata": {},
   "source": [
    "üó£Ô∏è **Instructor Talking Point**: \"Here we count how often each term appears in a single document and normalize it. This is the simplest way to represent word importance within a document. Explain this with respect to a future AI agent (chatbot) builds  builds context.\n",
    "<br/>\n",
    "<br/>\n",
    "üß† **Student Talking Point**: \"Use this TF output to compare with another document. Which terms are likely to be most important in Doc1 based on their normalized TF? Explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f347108",
   "metadata": {},
   "source": [
    "### üîπ Log Frequency Weight\n",
    "\n",
    "To reduce the impact of very frequent terms, **log frequency weighting** is applied.\n",
    "\n",
    "$$\n",
    "w_{t,d} =\n",
    "\\begin{cases}\n",
    "1 + \\log_{10}(f_{t,d}) & \\text{if } f_{t,d} > 0 \\\\\n",
    "0 & \\text{if } f_{t,d} = 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "This transformation reduces the skew caused by terms that appear many times in a document. Instead of allowing their raw frequency to dominate, we scale their contribution **logarithmically**.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Why Use It?\n",
    "\n",
    "- Frequent terms are not always the most **important** terms.\n",
    "- Log scaling ensures that:\n",
    "  - Words with a raw count of 1 are preserved ($1 + \\\\log_{10}(1) = 1$),\n",
    "  - But words with very high counts (e.g., 1000) don‚Äôt dominate the document vector.\n",
    "\n",
    "This helps **normalize the influence** of repetitive terms and improve the **numerical stability** of document representations in models.\n",
    "\n",
    "---\n",
    "\n",
    "#### üìò Example\n",
    "\n",
    "Let‚Äôs say we have a document with the following raw term counts:\n",
    "\n",
    "| Term     | Raw TF $f_{t,d}$ | Log Frequency Weight $w_{t,d}$ |\n",
    "|----------|------------------|-------------------------------|\n",
    "| machine  | 1                | $1 + \\\\log_{10}(1) = 1$        |\n",
    "| learning | 3                | $1 + \\\\log_{10}(3) \\approx 1.477$ |\n",
    "| data     | 10               | $1 + \\\\log_{10}(10) = 2$       |\n",
    "\n",
    "So even though \"data\" appears 10 times, its log-weighted value is **just 2**, making it more comparable to less frequent but potentially more meaningful terms like \"learning\".\n",
    "\n",
    "This makes log frequency weighting especially useful when preparing inputs for models like **TF-IDF** or **document clustering**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4bcea7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Log Frequency Weighting:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Term",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Raw TF (f_{t,d})",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Log Weight (w_{t,d})",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3c110564-b9ff-4da2-9c19-f6665e7bf9a9",
       "rows": [
        [
         "0",
         "machine",
         "2",
         "1.3010299956639813"
        ],
        [
         "1",
         "learning",
         "4",
         "1.6020599913279625"
        ],
        [
         "2",
         "data",
         "7",
         "1.845098040014257"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Raw TF (f_{t,d})</th>\n",
       "      <th>Log Weight (w_{t,d})</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>machine</td>\n",
       "      <td>2</td>\n",
       "      <td>1.301030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>learning</td>\n",
       "      <td>4</td>\n",
       "      <td>1.602060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data</td>\n",
       "      <td>7</td>\n",
       "      <td>1.845098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Term  Raw TF (f_{t,d})  Log Weight (w_{t,d})\n",
       "0   machine                 2              1.301030\n",
       "1  learning                 4              1.602060\n",
       "2      data                 7              1.845098"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üìò Example: Log Frequency Weighting\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Sample document with varying term frequencies\n",
    "doc = \"machine learning data data data learning learning learning machine data data data data\"\n",
    "\n",
    "# Tokenize and count raw term frequencies\n",
    "tokens = doc.lower().split()\n",
    "raw_tf = Counter(tokens)\n",
    "\n",
    "# Compute log frequency weights\n",
    "log_weighted_tf = {\n",
    "    term: 1 + np.log10(freq) if freq > 0 else 0\n",
    "    for term, freq in raw_tf.items()\n",
    "}\n",
    "\n",
    "# Build and display the result as a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Term\": raw_tf.keys(),\n",
    "    \"Raw TF (f_{t,d})\": raw_tf.values(),\n",
    "    \"Log Weight (w_{t,d})\": log_weighted_tf.values()\n",
    "})\n",
    "\n",
    "print(\"üìä Log Frequency Weighting:\")\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8278f040",
   "metadata": {},
   "source": [
    "üó£Ô∏è **Instructor Talking Point**: Note how 'data' has a high frequency, but its impact is smoothed by log weighting, making it comparable to 'learning'. Explain this with respect to how a future AI agent (chatbot) builds builds context.\n",
    "<br/>\n",
    "<br/>\n",
    "üß† **Student Talking Point**: Try adjusting the number of times a word appears and observe how the log scale compresses large values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da22b7",
   "metadata": {},
   "source": [
    "### üîπ Document Frequency (DF)\n",
    "\n",
    "**Document Frequency** is the number of documents in which a term $t$ appears:\n",
    "\n",
    "$$\n",
    "df_t = |\\{ d \\in D : t \\in d \\}|\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $df_t$ is the document frequency of term $t$\n",
    "- $D$ is the set of all documents in the corpus\n",
    "- $t \\in d$ means the term $t$ appears in document $d$\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Why Use It?\n",
    "\n",
    "- It helps you understand **how common or rare** a word is across the entire document set.\n",
    "- Words with **high DF** (e.g., ‚Äúthe‚Äù, ‚Äúand‚Äù) occur in many documents and are often **less informative**.\n",
    "- Words with **low DF** are more likely to be **specific and meaningful** for distinguishing between documents.\n",
    "- DF is a key ingredient in calculating **Inverse Document Frequency (IDF)**.\n",
    "\n",
    "---\n",
    "\n",
    "#### üìò Example\n",
    "\n",
    "Suppose you have the following three documents:\n",
    "\n",
    "- **Doc1**: \"machine learning is fun\"  \n",
    "- **Doc2**: \"deep learning is powerful\"  \n",
    "- **Doc3**: \"machine learning and deep models\"\n",
    "\n",
    "Now, let‚Äôs compute the Document Frequency:\n",
    "\n",
    "| Term     | Document Frequency ($df_t$) |\n",
    "|----------|-----------------------------|\n",
    "| machine  | 2 (Doc1, Doc3)              |\n",
    "| learning | 3 (Doc1, Doc2, Doc3)        |\n",
    "| deep     | 2 (Doc2, Doc3)              |\n",
    "| models   | 1 (Doc3)                    |\n",
    "\n",
    "The term **\"learning\"** appears in all three documents ‚Üí **high DF**, which means it‚Äôs **less useful for distinguishing** between them.\n",
    "\n",
    "The term **\"models\"** appears in only one document ‚Üí **low DF**, meaning it could be a **useful keyword** for that specific document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "993b6d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Document Frequency (DF) Table:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Term",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Document Frequency (df_t)",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "4304c08d-0922-4318-9901-414d7e1a80a5",
       "rows": [
        [
         "4",
         "learning",
         "3"
        ],
        [
         "1",
         "deep",
         "2"
        ],
        [
         "5",
         "machine",
         "2"
        ],
        [
         "3",
         "is",
         "2"
        ],
        [
         "2",
         "fun",
         "1"
        ],
        [
         "0",
         "and",
         "1"
        ],
        [
         "6",
         "models",
         "1"
        ],
        [
         "7",
         "powerful",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Document Frequency (df_t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>learning</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deep</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>machine</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fun</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>models</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>powerful</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Term  Document Frequency (df_t)\n",
       "4  learning                          3\n",
       "1      deep                          2\n",
       "5   machine                          2\n",
       "3        is                          2\n",
       "2       fun                          1\n",
       "0       and                          1\n",
       "6    models                          1\n",
       "7  powerful                          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üìò Example: Document Frequency (DF)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample documents from Curriculum Learning (4)\n",
    "docs = [\n",
    "    \"machine learning is fun\",          # Doc1\n",
    "    \"deep learning is powerful\",        # Doc2\n",
    "    \"machine learning and deep models\"  # Doc3\n",
    "]\n",
    "\n",
    "# Use CountVectorizer to extract term-document matrix (raw counts)\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(docs)\n",
    "\n",
    "# Get feature names and document-term matrix as array\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "X_array = X.toarray()\n",
    "\n",
    "# Calculate document frequency for each term\n",
    "df_counts = (X_array > 0).sum(axis=0)\n",
    "\n",
    "# Format as a DataFrame\n",
    "df_table = pd.DataFrame({\n",
    "    \"Term\": terms,\n",
    "    \"Document Frequency (df_t)\": df_counts\n",
    "}).sort_values(\"Document Frequency (df_t)\", ascending=False)\n",
    "\n",
    "print(\"üìä Document Frequency (DF) Table:\")\n",
    "display(df_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d74152",
   "metadata": {},
   "source": [
    "üó£Ô∏è **Instructor Talking Point**: Notice how common terms like 'learning' appear in all documents, while more specific terms like 'fun' or 'models' appear in only one.\n",
    "<br/>\n",
    "<br/>\n",
    "üß† **Student Talking Point**: Choose a term and explain how its document frequency could affect downstream TF-IDF weighting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9012a299",
   "metadata": {},
   "source": [
    "### üîπ Inverse Document Frequency (IDF)\n",
    "\n",
    "**Inverse Document Frequency (IDF)** measures how rare or informative a term is across the entire corpus:\n",
    "\n",
    "$$\n",
    "idf_t = \\log_{10} \\left( \\frac{N}{df_t} \\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $N$ is the total number of documents in the corpus  \n",
    "- $df_t$ is the number of documents that contain the term $t$\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Why Use It?\n",
    "\n",
    "- IDF is used to **downweight common terms** and **upweight rare ones**.\n",
    "- Words like ‚Äúthe‚Äù, ‚Äúand‚Äù, or ‚Äúdata‚Äù appear frequently and are less helpful in distinguishing documents.\n",
    "- Terms that appear in **fewer documents** are often **more informative** and **discriminative**.\n",
    "- IDF is a core component of **TF-IDF**, a widely used technique in search engines, document classification, and clustering.\n",
    "\n",
    "---\n",
    "\n",
    "#### üìò Example\n",
    "\n",
    "Let‚Äôs say we have **5 documents** total, and the following document frequencies:\n",
    "\n",
    "| Term     | $df_t$ | $idf_t = \\log_{10}(N / df_t)$ |\n",
    "|----------|--------|-------------------------------|\n",
    "| machine  | 3      | $\\log_{10}(5 / 3) \\approx 0.22$ |\n",
    "| entropy  | 1      | $\\log_{10}(5 / 1) = 0.70$       |\n",
    "| the      | 5      | $\\log_{10}(5 / 5) = 0.00$       |\n",
    "\n",
    "- The term **\"entropy\"** appears in only one document, so its IDF is **high** ‚Üí it‚Äôs a **rare and informative term**.\n",
    "- The term **\"the\"** ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4553c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Inverse Document Frequency (IDF) Table:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Term",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Document Frequency (df_t)",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "IDF (log10(N / df_t))",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "aa2a679d-c3a4-4404-b63f-59fb102e890f",
       "rows": [
        [
         "0",
         "advanced",
         "1",
         "0.6989700043360189"
        ],
        [
         "1",
         "ai",
         "1",
         "0.6989700043360189"
        ],
        [
         "2",
         "and",
         "1",
         "0.6989700043360189"
        ],
        [
         "3",
         "are",
         "1",
         "0.6989700043360189"
        ],
        [
         "4",
         "deep",
         "1",
         "0.6989700043360189"
        ],
        [
         "5",
         "entropy",
         "1",
         "0.6989700043360189"
        ],
        [
         "6",
         "evolving",
         "1",
         "0.6989700043360189"
        ],
        [
         "11",
         "of",
         "1",
         "0.6989700043360189"
        ],
        [
         "14",
         "science",
         "1",
         "0.6989700043360189"
        ],
        [
         "10",
         "measures",
         "1",
         "0.6989700043360189"
        ],
        [
         "13",
         "randomness",
         "1",
         "0.6989700043360189"
        ],
        [
         "12",
         "powerful",
         "1",
         "0.6989700043360189"
        ],
        [
         "15",
         "the",
         "1",
         "0.6989700043360189"
        ],
        [
         "7",
         "is",
         "2",
         "0.3979400086720376"
        ],
        [
         "9",
         "machine",
         "3",
         "0.2218487496163564"
        ],
        [
         "8",
         "learning",
         "4",
         "0.09691001300805642"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 16
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Document Frequency (df_t)</th>\n",
       "      <th>IDF (log10(N / df_t))</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>advanced</td>\n",
       "      <td>1</td>\n",
       "      <td>0.698970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ai</td>\n",
       "      <td>1</td>\n",
       "      <td>0.698970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>1</td>\n",
       "      <td>0.698970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>are</td>\n",
       "      <td>1</td>\n",
       "      <td>0.698970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deep</td>\n",
       "      <td>1</td>\n",
       "      <td>0.698970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.698970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>evolving</td>\n",
       "      <td>1</td>\n",
       "      <td>0.698970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>of</td>\n",
       "      <td>1</td>\n",
       "      <td>0.698970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>science</td>\n",
       "      <td>1</td>\n",
       "      <td>0.698970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>measures</td>\n",
       "      <td>1</td>\n",
       "      <td>0.698970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>randomness</td>\n",
       "      <td>1</td>\n",
       "      <td>0.698970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>powerful</td>\n",
       "      <td>1</td>\n",
       "      <td>0.698970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>the</td>\n",
       "      <td>1</td>\n",
       "      <td>0.698970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>machine</td>\n",
       "      <td>3</td>\n",
       "      <td>0.221849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>learning</td>\n",
       "      <td>4</td>\n",
       "      <td>0.096910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Term  Document Frequency (df_t)  IDF (log10(N / df_t))\n",
       "0     advanced                          1               0.698970\n",
       "1           ai                          1               0.698970\n",
       "2          and                          1               0.698970\n",
       "3          are                          1               0.698970\n",
       "4         deep                          1               0.698970\n",
       "5      entropy                          1               0.698970\n",
       "6     evolving                          1               0.698970\n",
       "11          of                          1               0.698970\n",
       "14     science                          1               0.698970\n",
       "10    measures                          1               0.698970\n",
       "13  randomness                          1               0.698970\n",
       "12    powerful                          1               0.698970\n",
       "15         the                          1               0.698970\n",
       "7           is                          2               0.397940\n",
       "9      machine                          3               0.221849\n",
       "8     learning                          4               0.096910"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üìò Example: Inverse Document Frequency (IDF)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample documents (5 total)\n",
    "docs = [\n",
    "    \"machine learning is powerful\",\n",
    "    \"deep learning is advanced\",\n",
    "    \"entropy measures randomness\",\n",
    "    \"machine learning and AI are evolving\",\n",
    "    \"the science of machine learning\"\n",
    "]\n",
    "\n",
    "# Total number of documents\n",
    "N = len(docs)\n",
    "\n",
    "# Use CountVectorizer to get document-term matrix\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(docs)\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "X_array = X.toarray()\n",
    "\n",
    "# Compute document frequency for each term\n",
    "df_counts = (X_array > 0).sum(axis=0)\n",
    "\n",
    "# Compute IDF using log base 10\n",
    "idf_values = np.log10(N / df_counts)\n",
    "\n",
    "# Build a DataFrame for display\n",
    "idf_table = pd.DataFrame({\n",
    "    \"Term\": terms,\n",
    "    \"Document Frequency (df_t)\": df_counts,\n",
    "    \"IDF (log10(N / df_t))\": idf_values\n",
    "}).sort_values(\"IDF (log10(N / df_t))\", ascending=False)\n",
    "\n",
    "print(\"üìä Inverse Document Frequency (IDF) Table:\")\n",
    "display(idf_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549fdf35",
   "metadata": {},
   "source": [
    "üó£Ô∏è **Instructor Talking Point**: IDF adjusts for the fact that some words are common across all documents ‚Äî this is critical in improving document relevance in search systems.\n",
    "<br/>\n",
    "<br/>\n",
    "üß† **Student Talking Point**: Choose a low-IDF and high-IDF term from this output and explain why they behave differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fe918e",
   "metadata": {},
   "source": [
    "### üîπ TF-IDF Weighting\n",
    "\n",
    "**TF-IDF (Term Frequency‚ÄìInverse Document Frequency)** scores each term $t$ in document $d$ based on how frequent and how rare it is:\n",
    "\n",
    "$$\n",
    "w_{t,d} = \\left(1 + \\log_{10}(f_{t,d})\\right) \\times \\log_{10} \\left( \\frac{N}{df_t} \\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $f_{t,d}$ is the raw count of term $t$ in document $d$\n",
    "- $df_t$ is the number of documents that contain term $t$\n",
    "- $N$ is the total number of documents in the corpus\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Why Use It?\n",
    "\n",
    "- TF-IDF balances **term importance within a document** (TF) against **term commonality across all documents** (IDF).\n",
    "- It **boosts rare, relevant words** while **suppressing frequent, generic words**.\n",
    "- TF-IDF is foundational in:\n",
    "  - Information Retrieval (search engines)\n",
    "  - Document similarity\n",
    "  - Feature engineering for classification or clustering\n",
    "\n",
    "---\n",
    "\n",
    "#### üìò Example\n",
    "\n",
    "Suppose we have:\n",
    "\n",
    "- $f_{\\text{machine}, \\text{Doc1}} = 3$\n",
    "- $df_{\\text{machine}} = 2$\n",
    "- $N = 5$ total documents\n",
    "\n",
    "Then:\n",
    "\n",
    "- TF part: $1 + \\log_{10}(3) \\approx 1 + 0.477 = 1.477$\n",
    "- IDF part: $\\log_{10}(5 / 2) \\approx 0.398$\n",
    "- TF-IDF weight:\n",
    "\n",
    "$$\n",
    "w_{\\text{machine}, \\text{Doc1}} = 1.477 \\times 0.398 \\approx 0.588\n",
    "$$\n",
    "\n",
    "This means \"machine\" is **important within Doc1**, but since it's found in other documents too, the overall weight is **moderated**.\n",
    "\n",
    "TF-IDF creates a **sparse, weighted vector representation** of documents, ready for:\n",
    "- Cosine similarity\n",
    "- Clustering\n",
    "- Search ranking\n",
    "- Input into classical machine learning models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33e9308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä TF-IDF Weighted Matrix (Manual Computation):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eespinosa\\AppData\\Local\\Temp\\ipykernel_44988\\4078578607.py:31: RuntimeWarning: divide by zero encountered in log10\n",
      "  tf_log = 1 + np.where(X_array > 0, np.log10(X_array), 0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "advanced",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ai",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "and",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "are",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "deep",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "entropy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "evolving",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "learning",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "machine",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "measures",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "of",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "powerful",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "randomness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "science",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "the",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "6f958495-4316-4c84-937c-2d0ebbe90a18",
       "rows": [
        [
         "Doc1",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.398",
         "0.097",
         "0.222",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699"
        ],
        [
         "Doc2",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.398",
         "0.097",
         "0.222",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699"
        ],
        [
         "Doc3",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.398",
         "0.097",
         "0.222",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699"
        ],
        [
         "Doc4",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.398",
         "0.097",
         "0.222",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699"
        ],
        [
         "Doc5",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.398",
         "0.097",
         "0.222",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699",
         "0.699"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>advanced</th>\n",
       "      <th>ai</th>\n",
       "      <th>and</th>\n",
       "      <th>are</th>\n",
       "      <th>deep</th>\n",
       "      <th>entropy</th>\n",
       "      <th>evolving</th>\n",
       "      <th>is</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>measures</th>\n",
       "      <th>of</th>\n",
       "      <th>powerful</th>\n",
       "      <th>randomness</th>\n",
       "      <th>science</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4</th>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc5</th>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      advanced     ai    and    are   deep  entropy  evolving     is  \\\n",
       "Doc1     0.699  0.699  0.699  0.699  0.699    0.699     0.699  0.398   \n",
       "Doc2     0.699  0.699  0.699  0.699  0.699    0.699     0.699  0.398   \n",
       "Doc3     0.699  0.699  0.699  0.699  0.699    0.699     0.699  0.398   \n",
       "Doc4     0.699  0.699  0.699  0.699  0.699    0.699     0.699  0.398   \n",
       "Doc5     0.699  0.699  0.699  0.699  0.699    0.699     0.699  0.398   \n",
       "\n",
       "      learning  machine  measures     of  powerful  randomness  science    the  \n",
       "Doc1     0.097    0.222     0.699  0.699     0.699       0.699    0.699  0.699  \n",
       "Doc2     0.097    0.222     0.699  0.699     0.699       0.699    0.699  0.699  \n",
       "Doc3     0.097    0.222     0.699  0.699     0.699       0.699    0.699  0.699  \n",
       "Doc4     0.097    0.222     0.699  0.699     0.699       0.699    0.699  0.699  \n",
       "Doc5     0.097    0.222     0.699  0.699     0.699       0.699    0.699  0.699  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üìò Example: TF-IDF Weighting (Manual Computation)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample corpus of 5 documents\n",
    "docs = [\n",
    "    \"machine learning is powerful\",\n",
    "    \"deep learning is advanced\",\n",
    "    \"entropy measures randomness\",\n",
    "    \"machine learning and AI are evolving\",\n",
    "    \"the science of machine learning\"\n",
    "]\n",
    "\n",
    "# Total number of documents\n",
    "N = len(docs)\n",
    "\n",
    "# Vectorize (raw term frequencies)\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(docs)\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "X_array = X.toarray()\n",
    "\n",
    "# Compute Document Frequencies\n",
    "df = (X_array > 0).sum(axis=0)\n",
    "idf = np.log10(N / df)\n",
    "\n",
    "# Manual TF-IDF: apply (1 + log10(tf)) * idf\n",
    "tf_log = 1 + np.where(X_array > 0, np.log10(X_array), 0)\n",
    "tfidf = tf_log * idf\n",
    "\n",
    "# Create a DataFrame for visual inspection\n",
    "tfidf_df = pd.DataFrame(tfidf, columns=terms, index=[f\"Doc{i+1}\" for i in range(N)])\n",
    "\n",
    "print(\"üìä TF-IDF Weighted Matrix (Manual Computation):\")\n",
    "display(tfidf_df.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131478c9",
   "metadata": {},
   "source": [
    "üó£Ô∏è **Instructor Talking Point**: We combined TF and IDF manually ‚Äî useful for seeing how each part of the formula shapes the final result.\n",
    "<br/>\n",
    "<br/>\n",
    "üó£Ô∏è **Instructor Talking Point**: Document Frequency (DF) counts how many documents contain a specific term, showing how common it is across the corpus.\n",
    "Inverse Document Frequency (IDF) does the opposite‚Äîit measures how rare or informative a term is by applying a logarithmic scale to the inverse of DF.\n",
    "So, DF increases with term frequency across documents, while IDF decreases, giving higher weight to rare terms.\n",
    "Together, they balance relevance: DF tells us \"how many use this term,\" while IDF tells us \"how useful is this term for distinguishing documents.\"\n",
    "IDF is critical for reducing noise from overly common words.\n",
    "<br/>\n",
    "<br/>\n",
    "üß† **Student Talking Point**: \"Pick one row (a document) and explain which term seems most important and why, based on the TF-IDF weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb2a938",
   "metadata": {},
   "source": [
    "## Step 2: Document Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc648f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: Load documents from a local folder\n",
    "import os\n",
    "corpus = []\n",
    "for filename in os.listdir('data'):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join('data', filename), 'r', encoding='utf-8') as file:\n",
    "            corpus.append(file.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8034f9",
   "metadata": {},
   "source": [
    "## Step 3: Implement a Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e744d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machine', 'learning', 'is', 'fun!']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from typing import List\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    return text.lower().split()\n",
    "\n",
    "# Example\n",
    "tokenize(\"Machine Learning is Fun!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd760f4",
   "metadata": {},
   "source": [
    "## Step 4: Text Normalization Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d53f7134",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def normalize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t not in stopwords.words('english')]\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(t) for t in tokens]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee9bc1c",
   "metadata": {},
   "source": [
    "## Step 5: Build and Test the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae23ce7b",
   "metadata": {},
   "source": [
    "\n",
    "Using the six concepts and the preprocessing pipeline above, implement a full pipeline that:\n",
    "- Preprocesses text\n",
    "- Applies vectorization\n",
    "- Computes all six concept metrics\n",
    "- Tests with one phrase query per concept\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95d8b6b",
   "metadata": {},
   "source": [
    "## Step 6: The Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a255c3d",
   "metadata": {},
   "source": [
    "\n",
    "One team member must push the final notebook to GitHub and send the `.git` URL to the instructor before the end of class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74c4ae5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## üß† Learning Objectives\n",
    "- Implement the foundations of **Vector Space Proximity** algorithms using real-world data during the NLP process.\n",
    "- Build **Jupyter Notebooks** with well-structured code and clear Markdown documentation.\n",
    "- Use **Git and GitHub** for collaborative version control and code sharing.\n",
    "- Identify and articulate coding issues (\"**talking points**\") and insert them directly into peer notebooks.\n",
    "- Practice **collaborative debugging**, professional peer feedback, and improve code quality.\n",
    "\n",
    "## üß© Workshop Structure (90 Minutes)\n",
    "1. **Instructor Use Case Introduction** *(15 min)* ‚Äì Set up teams of 3 people. Read and understand the workshop, plus submission instructions. Seek assistance if needed.\n",
    "2. **Team Jupyter Notebook Development** *(45 min)* ‚Äì NLP Pipeline and six IR basics techniques implementation + Markdown documentation (work as teams)\n",
    "3. **Push to GitHub** *(15 min)* ‚Äì Teams commit and push initial notebooks. **Make sure to include your names so it is easy to identify the team that developed the code**.\n",
    "4. **Instructor Review** - The instructor will go around, take notes, and provide coaching as needed, during the **Peer Review Round**\n",
    "5. **Email Delivery** *(15 min)* ‚Äì Each team send the instructor an email **with the *.git link** to the GitHub repo **(one email/team)**. Subject on the email is: PROG8245 - IR Basics & Vector Space Proximity Foundations Workshop, Team #_____.\n",
    "\n",
    "\n",
    "## üíª Submission Checklist\n",
    "- ‚úÖ `IRBasics_VectorSpaceProximity.ipynb` with:\n",
    "  - Demo code: Document Collection, Tokenizer, Normalization Pipeline, Inverted Index and the six concepts.\n",
    "  - Markdown explanations for each major step\n",
    "  - **Labeled talking point(s)** (1-2 per concept)\n",
    "- ‚úÖ `README.md` with:\n",
    "  - Dataset description\n",
    "  - Team member names\n",
    "  - Link to the dataset and license (if public)\n",
    "- ‚úÖ GitHub Repo:\n",
    "  - Public repo named `IRBasics-VectorSpaceProximity-workshop`\n",
    "  - This is a group effort, so **choose one member of the team** to publish the repo\n",
    "  - At least **one commit containing one meaningful talking point**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5055fbe9",
   "metadata": {},
   "source": [
    "## üîö Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27358c8e",
   "metadata": {},
   "source": [
    "\n",
    "This workshop prepares you for our next session on **Vector Space Proximity** and **Cosine Similarity**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
